# SFT (Supervised Fine-Tuning) ile TinyLlama EÄŸitimi

Bu proje, Hugging Face `transformers` ve `peft` (QLoRA) kÃ¼tÃ¼phanelerini kullanarak `TinyLlama-1.1B-Chat-v1.0` modelini (veya benzeri bir modeli) talimat verileriyle (instruction data) ince ayar (fine-tuning) yapmak iÃ§in kullanÄ±lÄ±r.

Kod, `transformers.Trainer` sÄ±nÄ±fÄ±nÄ± temel alÄ±r ve `trl` kÃ¼tÃ¼phanesinin `SFTTrainer` sÄ±nÄ±fÄ±na bir alternatif olarak Ã§alÄ±ÅŸÄ±r.

##  Ã–zellikler

* **QLoRA:** 4-bit kuantizasyon ile (CUDA GPU varsa) verimli eÄŸitim.
* **ModÃ¼ler YapÄ±:** Veri iÅŸleme, model sÄ±nÄ±fÄ± ve eÄŸitim script'i birbirinden ayrÄ±lmÄ±ÅŸtÄ±r.
* **Esnek Veri YÃ¼kleme:** Hugging Face Hub'dan (`timdettmers/openassistant-guanaco`) veya yerel `.jsonl` dosyasÄ±ndan Ã¶zel veri yÃ¼kleme.
* **CLI DesteÄŸi:** `argparse` ile model, veri seti, epoch gibi parametreleri komut satÄ±rÄ±ndan kolayca deÄŸiÅŸtirme.
* **Test Script'leri:** EÄŸitim sonrasÄ± modeli test etmek iÃ§in `train.py` iÃ§inde ve ayrÄ± bir `inference.py` script'i.


## ğŸ› ï¸ Kurulum

1.  **Depoyu Klonlama:**
    ```bash
    git clone [https://github.com/AbdulSametTurkmenoglu/sft_fine_tuning.git](https://github.com/AbdulSametTurkmenoglu/sft_fine_tuning.git)
    cd sft_fine_tuning
    ```

2.  **Sanal Ortam :**
    ```bash
    python -m venv .venv
    .\.venv\Scripts\activate
    
    python3 -m venv .venv
    source .venv/bin/activate
    ```

3.  **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleme:**
    ```bash
    pip install -r requirements.txt
    ```
    *Not: CUDA ortamÄ± iÃ§in `torch` kurulumunuzun GPU destekli olduÄŸundan emin olun.*

##  KullanÄ±m

### 1. Modeli EÄŸitme

Ana eÄŸitim script'i `train.py`'dir.

**Ã–rnek 1: Ã–zel `custom_instructions.jsonl` verisi ile eÄŸitim (VarsayÄ±lan):**
(Bu, `data/` klasÃ¶rÃ¼ndeki teknik Q&A verisini kullanÄ±r)

```bash
python train.py
```

**Ã–rnek 2: Hugging Face Hub'dan "Guanaco" verisi ile eÄŸitim:**

```bash
python train.py --dataset guanaco --guanaco_samples 1000 --output_dir sft_guanaco_model
```

**Ã–rnek 3: FarklÄ± bir model ve epoch sayÄ±sÄ± ile eÄŸitim:**

```bash
python train.py --model_name "google/gemma-2b" --epochs 5 --output_dir sft_gemma_model
```

TÃ¼m argÃ¼manlarÄ± gÃ¶rmek iÃ§in:
```bash
python train.py --help
```

### 2. EÄŸitilmiÅŸ Model ile Ã‡Ä±karÄ±m (Inference)

EÄŸitim tamamlandÄ±ÄŸÄ±nda (`sft_tinyllama_model` klasÃ¶rÃ¼ oluÅŸtuÄŸunda), `inference.py` script'ini kullanarak modelle sohbet edebilirsiniz.

Bu script, LoRA adaptÃ¶rÃ¼nÃ¼ ana modelle birleÅŸtirir (`merge_and_unload`) ve hÄ±zlÄ± Ã§Ä±karÄ±m saÄŸlar.

```bash
python inference.py --model_path sft_tinyllama_model
```

EÄŸer farklÄ± bir model veya Ã§Ä±ktÄ± klasÃ¶rÃ¼ kullandÄ±ysanÄ±z:
```bash
python inference.py --base_model "google/gemma-2b" --model_path "sft_gemma_model"
```